{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "To get started, we will prototype the workflow locally.\n",
    "\n",
    "**Warning:** this notebook may fail if your local machine does not have sufficient resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install requirements\n",
    "\n",
    "Install required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade dask distributed bokeh fastparquet adlfs xgboost pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "\n",
    "The data is modified from a Kaggle competition and hosted publicly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start a distributed Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "\n",
    "c = Client()\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize the Pythonic filesystem\n",
    "\n",
    "**Tip:** if you're not using public data, you need to provide data credentials. These can be retrieved through Azure ML Datastores, e.g.:\n",
    "\n",
    "```python\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ds = ws.get_default_datastore() # ws.datastores[\"my-datastore-name\"]\n",
    "\n",
    "storage_options = {\n",
    "    \"account_name\": ds.account_name,\n",
    "    \"account_key\": ds.account_key\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adlfs import AzureBlobFileSystem\n",
    "\n",
    "container_name = \"malware\"\n",
    "storage_options = {\"account_name\": \"azuremlexamples\"}\n",
    "\n",
    "fs = AzureBlobFileSystem(**storage_options)\n",
    "fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list the processed (partitioned) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = fs.ls(f\"{container_name}/processed\")\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data into a (dask) dataframe - note pandas also accepts the ``storage_options`` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "for f in files:\n",
    "    if \"train\" in f:\n",
    "        df_train = dd.read_parquet(f\"az://{f}\", storage_options=storage_options)\n",
    "    elif \"test\" in f:\n",
    "        df_test = dd.read_parquet(f\"az://{f}\", storage_options=storage_options)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup remote tracking\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "tracking_uri = ws.get_mlflow_tracking_uri()\n",
    "tracking_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import xgboost as xgb \n",
    "\n",
    "def train_a_model(tracking_uri, df, params, num_boost_round=10):\n",
    "    # setup remote tracking\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    mlflow.set_experiment(\"many-models-experiments\")\n",
    "\n",
    "    # turn on autolog\n",
    "    mlflow.xgboost.autolog()\n",
    "\n",
    "    # load in dataframe\n",
    "    df = df.compute() \n",
    "\n",
    "    # throw out non-numeric columns [insert real data prep here]\n",
    "    cols = [col for col in df.columns if df.dtypes[col] != \"object\"]\n",
    "    data = df[cols].drop(\"HasDetections\", axis=1).values\n",
    "    label = df[\"HasDetections\"].values\n",
    "\n",
    "    # train xgboost\n",
    "    dtrain = xgb.DMatrix(data, label=label)\n",
    "    model = xgb.train(params, dtrain, num_boost_round=num_boost_round)\n",
    "\n",
    "    # return model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 10\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"gamma\": 0,\n",
    "    \"max_depth\": 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [c.submit(train_a_model, tracking_uri, df, params, num_boost_round=num_boost_round) for df in df_train.partitions]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dkdc': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6813bb6deec483ed15ac37ef074baa52622250b2b65156cf2f3313d85d7e0391"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}